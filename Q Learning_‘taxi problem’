# -*- coding: utf-8 -*-
"""
Created on Fri Oct 18 09:21:55 2019
Q Learning_taxi problem

on-policy: epsilon-greedy
off-policy: 
@author: 63159
"""
import gym
import random
env = gym.make('Taxi-v1')
env.render()
alpha = 0.4
gamma = 0.999
epsilon = 0.017
q={}
for s in range(env.observation_space.n):
    for a in range(env.action_space.n):
        q[(s,a)]=0
def update_q_table(prev_state,action,reward,nextstate,alpha,gamma):
    qa=max([q[(nextstate,a)] for a in range(env.action_space.n)])
    q[(prev_state,action)]+=alpha*(reward+gamma*qa-q[(prev_state,action)])
def epsilon_greedy_policy(state,epsilon):
    if random.uniform(0,1)<epsilon:
        return env.action_space.sample
    else:
        return max(list(range(env.action_space.n)), key=lambda x: q[(state,x)])
for i in range(8000):
    r=0
    prev_state=env.reset()
    while True:
        action=epsilon_greedy_policy(prev_state,epsilon)
        next_state,reward,done,_=env.step(action)
        update_q_table(prev_state,action,reward,next_state,alpha,gamma)
        prev_state=next_state
        r+=reward
        if done:
            break
    print("total reward: ",r)
env.close()
